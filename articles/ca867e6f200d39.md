---
title: "AWS Bedrockで回答の続きを取得する方法"
emoji: "💭"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["aws", "bedrock", "python", "anthropic"]
published: true
---

## 方法

- `invoke_model`を使います。
- レスポンスが `"stop_reason": "max_tokens"` のとき、`messages` に `{"role": "assistant", "content": [{"type": "text", "text": {生成されたテキスト}}]`を追加して、再度`invoke_model`を実行します。
- レスポンスが `"stop_reason": "end_turn"` になるまで続けます。

## 環境

- Python 3
- boto3
- モデル: Claude 3 Haiku

## サンプルコード

`max_tokens` で打ち切られるたびに応答を再リクエストし、生成されたテキストを連結しています。`stop_reason` が `"end_turn"` になるまでこれを繰り返す仕組みです。

```python
#!/usr/bin/env python
import json

import boto3

client = boto3.client("bedrock-runtime")
model_id = "anthropic.claude-3-haiku-20240307-v1:0"


def main() -> str:
    full_text = ""
    body_params = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 10,   # 意図的に小さい値にしています
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "カエルについての俳句を作ってください"},
                ],
            },
        ],
    }

    while True:
        params = {
            "modelId": model_id,
            "body": json.dumps(body_params),
            "accept": "application/json",
            "contentType": "application/json",
        }

        print("Invoking model...")
        response = client.invoke_model(**params)
        response_body = json.loads(response.get("body").read())

        for content in response_body.get("content", []):
            full_text += content["text"].strip()

        stop_reason = response_body["stop_reason"]
        print("Stop reason: ", stop_reason)
        if stop_reason != "max_tokens":
            break

        body_params["messages"].append(
            {
                "role": "assistant",
                "content": [{"type": "text", "text": full_text}],
            },
        )

    return full_text


if __name__ == "__main__":
    generated_text = main()

    print("--------------------------")
    print(generated_text)
```

### 実行結果例

```txt
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  max_tokens
Invoking model...
Stop reason:  end_turn
--------------------------
はい、カエルについての俳句を作ってみました。

池のほとりで
静かに鳴く小さな声夕暮れの影自然の中でのカエル。静かに響く声、そして夕暮れの静けさを感じさせてくれます。
```

## Converse API ではできない？

Converse API で同じように回答の続きを取得しようとすると、以下エラーが発生します。

> botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the Converse operation: A conversation must alternate between user and assistant roles. Make sure the conversation alternates between user and assistant roles and try again.

回答の続きを得ようと試行錯誤しましたが、上手くいかず上記方法に落ち着きました。

Converse API は便利なので融通が利くとさらに嬉しいですね。
